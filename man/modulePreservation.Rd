% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modulePreservation.R
\name{modulePreservation}
\alias{modulePreservation}
\title{Replication and preservation of network modules across datasets}
\usage{
modulePreservation(data = NULL, correlation, network, moduleAssignments,
  discovery = 1, test = 2, nCores = 1, nPerm, exclude, include,
  null = "overlap", alternative = "greater", statCorMethod = "pearson",
  simplify = TRUE, verbose = TRUE, keepNulls = FALSE)
}
\arguments{
\item{data}{a list of numeric matrices. Each entry of the list corresponds to
a dataset and contains the data used to infer the interaction network
between variables (e.g. genes). Expects matrix columns to correspond to
variables and matrix rows to correspond to samples.}

\item{correlation}{a list of matrices. Each entry of the list corresponds to a 
dataset and contains an \eqn{n * n} matrix of the correlation between 
each pair of variables in the dataset.}

\item{network}{a list of matrices. Each entry of the list corresponds to a 
dataset and contains an \eqn{n * n} matrix of the network edge weights 
between each pair of variables in the dataset.}

\item{moduleAssignments}{a vector containing the module each variable belongs
to in the discovery dataset. If there are multiple discovery datasets 
then this argument should be a list of such vectors.}

\item{discovery}{name or index denoting the discovery dataset(s).}

\item{test}{name or index denoting the dataset(s) to test module preservation 
in.}

\item{nCores}{number of cores to parallelise the permutation procedure over.}

\item{nPerm}{number of permutations to use. Can be specified as a vector if
a different number of permutations is desired for each discovery dataset.
If not specified, the number of permutations will be automatically 
determined (see details).}

\item{exclude}{an optional vector of modules to exclude from the analysis. If
there are multiple discovery datasets a list of vectors may be provided.}

\item{include}{an optional vector of modules to include in the
analysis. If there are multiple discovery datasets a list of vectors may be
provided.}

\item{null}{variables to include when generating the null distributions. 
Must be either "overlap" or "all" (see details).}

\item{alternative}{The type of module preservation test to perform. Must be 
one of "greater" (default), "less" or "two.sided" (see details).}

\item{simplify}{logical; if \code{TRUE}, simplify the structure of the output
list if possible (see Return Value).}

\item{verbose}{logical; should progress be reported? Default is \code{TRUE}.}

\item{keepNulls}{logical; if \code{TRUE}, the null distributions are returned
as part of the output.}
}
\value{
The returned data structure is organised as a nested list of lists, which 
 should be accessed as \code{results[[discovery]][[test]]}. If
 \code{simplify} is set to \code{TRUE}, then this structure will be 
 simplified as much as possible depending on the combination of dataset 
 comparisons that have been performed. For each dataset-comparison a list of
 the following objects are returned:
 \itemize{
   \item{\code{observed}:}{
     A matrix of the observed values for the module preservation statistics.
     Rows correspond to modules, and columns to the module preservation
     statistics.
   }
   \item{\code{nulls}:}{
     A three dimensional array containing the values of the module 
     preservation statistics evaluated on random permutation of module 
     assignment in the test network. Rows correspond to modules, columns to
     the module preservation statistics, and the third dimension to the 
     permutations.
   }
   \item{\code{p.values}:}{
     A matrix of p-values for the \code{observed} module preservation 
     statistics as evaluated through a permutation test using the 
     corresponding values in \code{nulls}.
   }
   \item{\code{nVarsPresent}:}{
     A vector containing the number of variables that are present in the test
     dataset for each module.
   }
   \item{\code{propVarsPresent}:}{
     A vector containing the proportion of variables present in the test dataset
     for each module. Modules where this is less than 1 should be 
     investigated further before making judgements about preservation to 
     ensure that the missing variables are not the most connected ones.
   }
   \item{\code{contingency}:}{ 
     If \code{moduleAssignments} are present for both the \emph{discovery}
     and \emph{test} datasets, then a contigency table showing the overlap
     between modules across datasets is returned. Rows correspond to modules
     in the \emph{discovery} dataset, columns to modules in the \emph{test}
     dataset.
   }
 }
}
\details{
\subsection{Input data structure:}{
  This function allows for input data formatted in a number of ways. Where 
  there are multiple datasets of interest (e.g. multiple tissues, locations, 
  or a discovery dataset and an independent test dataset) the arguments 
  \code{data}, \code{correlation}, and \code{network} should be
  \code{\link[=list]{lists}} where each element contains the matrix data for 
  each respective dataset. Alternatively, if only one dataset is of interest, 
  the \code{data}, \code{correlation}, and \code{network} arguments
  will also each accept a 'matrix' object.
  
  Similarly, the \code{moduleAssignments} argument expects a list of named
  vectors, which denote the module each variable belongs to in the discovery
  dataset. If module discovery has only been performed in one dataset, then 
  the \code{moduleAssignments} argument will also accept a named vector.
  
  The \code{discovery} arguments specifies which dataset the \code{modules} 
  of interest were discovered in, and the \code{test} argument specifies 
  which dataset to calculate the network properties in. These arguments are
  ignored if data is provided for only one dataset.
}
\subsection{'bigMatrix' vs. 'matrix' input data:}{
  Although the function expects \code{\link[=bigMatrix-class]{bigMatrix}} 
  data, regular 'matrix' objects are also accepted. In this case, the 
  'matrix' data is temporarily converted to 'bigMatrix' by the function. This
  conversion process involves writing out each matrix as a binary file on 
  disk, which can take a long time for large datasets. It is strongly 
  recommended for the user to store their data as 'bigMatrix' objects, as the
  \link{modulePreservation} function, \link[=plotModule]{plotting} 
  \link[=plotTopology]{functions}, \link[=nodeOrder]{node} and 
  \link[=sampleOrder]{sample} ordering functions also expect 'bigMatrix'
  objects. Further, 'bigMatrix' objects have a number of benefits, including 
  instantaneous load time from any future R session, and parallel access from
  mutliple independent R sessions. Methods are provided for 
  \link[=bigMatrix-get]{converting to, loading in}, and 
  \link[=bigMatrix-out]{writing out} 'bigMatrix' objects.
}
\subsection{Memory usage:}{
  A trade off has been made between memory usage and computation time. 
  'modulePreservation' has a large memory overhead as it requires 
  pre-computed correlation and network matrices for each dataset. However,
  these are stored in shared memory, which means that each parallel process
  can independently access this memory. There is very little memory overhead
  for each additional core. 
  
  Although this also means that the matrices can be larger than the available
  RAM, in practice we find that this slows down the procedure by several 
  orders of magnitude. For optimal performance, there should be sufficient
  memory to load in each gene expression, correlation, and network matrix
  for each dataset. Note: most of this memory is cached; matrices are only 
  loaded into RAM when needed (i.e. for the dataset pair for a comparison),
  so the physical amount of RAM used will be much lower.
}
\subsection{Module Preservation Statistics:}{
 Module preservation is assessed through seven statistics \emph{(1)}:
 \enumerate{
   \item{\code{density}:}{
     The mean network edge weight of the module in the test dataset. Is the
     module more (or less) densely connected than expected by chance? 
   }
   \item{\code{propVarExpl}:}{
     The proportion of module varaince explained by the module summary 
     vector in the test dataset. The module summary vector is calculated as
     the first eigenvector from a principal component analysis on the
     module's data. For weighted gene coexpression networks this corresponds 
     to the "module eigengene (ME)" \emph{(1)}. Is the module more (or less)
     coherent than expected by chance?
   }
   \item{\code{cor.cor}:}{
     The correlation of the module's correlation structure across datasets. 
     Is the correlation structure more (or less) similar than expected by 
     chance?
   }
   \item{\code{cor.kIM}:}{
     The correlation of within-module connectivity (sum of edge weights to 
     all other nodes, i.e. a "weighted" node degree) across datasets. Are the
     relative node connectivities more similar than expected by chance?
   }
   \item{\code{cor.MM}:}{
     The correlation of module membership across datasets. Module membership 
     quantifies how strongly each variable composing a module contributes to 
     the module's summary vector. It is calculated as the correlation between
     the variable and the module summary vector. The statistic is abbreviated 
     as \code{cor.kME} in \emph{(1)}. Are the node contributions to the 
     module summary vector more similar than expected by chance?
   }
   \item{\code{mean.cor}:}{
     The mean correlation in the test dataset. It quantifies how strongly 
     correlated variables composing a module are in the test dataset, 
     penalising any variables where the sign of the correlation flips across
     datasets. It is also referred to as the "mean sign-aware correlation"
     (see \emph{(1)}). Is the correlation structure stronger than expected
     by chance?
   }
   \item{\code{mean.MM}:}{
     The mean module membership in the test dataset. It quantifies how 
     coherent the module is, penalising any variables where the sign of the 
     contribution flips across datasets (e.g. differential expression in one
     dataset but not the other). It is also abbreivated as \code{mean.kME} 
     in \emph{(1)}. Is the mean contribution of variables composing a module
     to the module stronger than expected by chance?
   }
 }
}
\subsection{Hypothesis testing:}{
 Three alternative hypotheses are available. "greater", the default, tests
 whether each module preservation statistic is larger than expected by 
 chance. "lesser" tests whether each module preservation statistic is smaller
 than expected by chance, which may be useful for identifying modules that
 are extremely different in the \emph{test} dataset. "two.sided" can be used
 to test both alternate hypotheses.
 
 To determine whether a module preservation statistic deviates from chance, a
 permutation procedure is employed. Each statistic is calculated between the
 module in the \emph{discovery} dataset and \code{nPerm} random subsets of
 the same size in the \emph{test} dataset in order to assess the distribution
 of each statistic under the null hypothesis. Two models for the null 
 hypothesis are available. Under "overlap", the default, random sampling is
 performed only for the set of variables present in both the \emph{discovery} and
 \emph{test} datasets. Alternatively, the argument \code{null} can be set to
 "all", in which case random sampling is performed on all variables present in
 the \emph{test} dataset.
  
 The number of permutations required for any given significance threshold is 
 approximately 1 / the desired significance for one sided tests, and double 
 that for two-sided tests. This can be calculated with 
 \code{\link{requiredPerms}}. When \code{nPerm} is not specified, the number 
 of permutations is automatically calculated as the number required for a 
 Bonferroni corrected significance threshold adjusting for the total number 
 of tests for each statistic, i.e. the total number of modules to be analysed
 multiplied by the number of \emph{test} datasets each module is tested in. 
 Although assessing the replication of a small numberof modules calls for 
 very few permutations, we recommend using no fewer than 1,000 as fewer 
 permutations are unlikely to generate representative null distributions. 
 \strong{Note:} the assumption used by \code{\link{requiredPerms}} to 
 determine the correct number of permtutations breaks down when assessing the
 preservation of modules in a very small dataset (e.g. gene sets in a dataset
 with less than 100 genes total). However, the reported p-values will still
 be accurate (see \code{\link{perm.test}}) \emph{(2)}.
}
}
\examples{
\dontrun{
set.seed(1)

## Example 1: Assess replication of all modules from one 
## cohort in an independent dataset

# First we need some example data
geA <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geA) <- paste0("Gene_", 1:100)
rownames(geA) <- paste0("CohortA_", 1:50)
coexpA <- cor(geA) # correlation
adjA <- abs(coexpA)^5 # adjacency
moduleAssignments <- sample(1:7, size=100, replace=TRUE)
names(moduleAssignments) <- paste0("Gene_", 1:100)

geB <- matrix(rnorm(70*100), ncol=100) # gene expression
colnames(geB) <- paste0("Gene_", 1:100) 
rownames(geB) <- paste0("CohortB_", 1:70)
coexpB <- cor(geB) # correlation
adjB <- abs(coexpB)^6 # adjacency

# Now format the data for input to modulePreservation
data <- list(
  cohortA=as.bigMatrix(geA, "geA_bm"),
  cohortB=as.bigMatrix(geA, "geA_bm")    
)
correlation <- list(
  cohortA=as.bigMatrix(coexpA, "coexpA_bm"),
  cohortB=as.bigMatrix(coexpB, "coexpB_bm")
)
adjacency <- list(
  cohortA=as.bigMatrix(adjA, "adjA_bm"),
  cohortB=as.bigMatrix(adjB, "adjB_bm")
)

# Assess module preservation, using two cores
replication <- modulePreservation(
  data, correlation, adjacency, moduleAssignments, 
  nCores=2
)

## Example 2: assess replication of two disease-associated modules
replication <- modulePreservation(
  data, correlation, adjacency, moduleAssignments,
  nCores=2, include = c("4", "7")
)

## Example 3: exclude a module from the analysis
replication <- modulePreservation(
  data, correlation, adjacency, moduleAssignments,
  nCores=2, exclude = "0"
)

## Example 4: assess preservation of modules across multiple
## tissues
geAdipose <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geAdipose) <- paste0("Gene_", 1:100)
rownames(geAdipose) <- paste0("Sample_", 1:50)
coexpAdipose <- cor(geAdipose) # correlation
adjAdipose <- abs(coexpAdipose)^5 # adjacency
adiposeModules <- sample(0:7, size=100, replace=TRUE)
names(adiposeModules) <- paste0("Gene_", 1:100)

geLiver <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geLiver) <- paste0("Gene_", 1:100)
rownames(geLiver) <- paste0("Sample_", 1:50)
coexpLiver <- cor(geLiver) # correlation
adjLiver <- abs(coexpLiver)^6 # adjacency
liverModules <- sample(0:12, size=100, replace=TRUE)
names(liverModules) <- paste0("Gene_", 1:100)

geHeart <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geHeart) <- paste0("Gene_", 1:100)
rownames(geHeart) <- paste0("Sample_", 1:50)
coexpHeart <- cor(geHeart) # correlation
adjHeart <- abs(coexpHeart)^4 # adjacency
heartModules <- sample(0:5, size=100, replace=TRUE)
names(heartModules) <- paste0("Gene_", 1:100)

# Now format the data for input to modulePreservation
data <- list(
  adipose=as.bigMatrix(geAdipose, "geAdipose_bm"),
  liver=as.bigMatrix(geLiver, "geLiver_bm"),  
  heart=as.bigMatrix(geHeart, "geHeart_bm") 
)
correlation <- list(
  adipose=as.bigMatrix(coexpAdipose, "coexpAdipose_bm"),
  liver=as.bigMatrix(coexpLiver, "coexpLiver_bm"),  
  heart=as.bigMatrix(coexpHeart, "coexpHeart_bm") 
)
adjacency <- list(
  adipose=as.bigMatrix(adjAdipose, "adjAdipose_bm"),
  liver=as.bigMatrix(adjLiver, "adjLiver_bm"),  
  heart=as.bigMatrix(adjHeart, "adjHeart_bm") 
)
moduleAssignments <- list(
  adipose=adiposeModules, liver=liverModules, heart=heartModules
)

# Assess the preservation of each module in each non-discovery
# tissue.
preservation <- modulePreservation(
  data, correlation, adjacency, moduleAssignments,
  nCores=2, discovery=c("adipose", "liver", "heart"), 
  test=c("adipose", "liver", "heart")
)

# Remove bigMatrix files used in examples
unlink("*_bm*")
}

}
\references{
\enumerate{
    \item{
      Langfelder, P., Luo, R., Oldham, M. C. & Horvath, S. \emph{Is my
      network module preserved and reproducible?} PLoS Comput. Biol. 
      \strong{7}, e1001057 (2011). 
    }
    \item{
      Phipson, B. & Smyth, G. K. \emph{Permutation P-values should never be 
      zero: calculating exact P-values when permutations are randomly drawn.}
      Stat. Appl. Genet. Mol. Biol. \strong{9}, Article39 (2010). 
    }
    \item{
      Langfelder, P. & Horvath, S. \emph{WGCNA: an R package for weighted 
      correlation network analysis.} BMC Bioinformatics \strong{9}, 559 
      (2008).
    }
  }
}

