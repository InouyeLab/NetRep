% Generated by roxygen2 (4.0.2): do not edit by hand
\name{modulePreservation}
\alias{modulePreservation}
\title{Replication and preservation of network modules across datasets}
\usage{
modulePreservation(geneExpression = NULL, coexpression, adjacency,
  moduleAssignments, discovery = 1, test = 2, nCores = 1, nPerm,
  excludeModules, includeModules, null = "overlap", alternative = "greater",
  simplify = TRUE, verbose = TRUE, keepNulls = FALSE)
}
\arguments{
\item{geneExpression}{A list of gene expression matrices, one for each
dataset. Expects columns to be genes, rows to be samples.}

\item{coexpression}{A list of coexpression matrices, one for each dataset.}

\item{adjacency}{A list of adjacency matrices, one for each dataset.}

\item{moduleAssignments}{A list of vectors for each \emph{discovery} dataset
containing the module assignments for each gene in the respective dataset.}

\item{discovery}{datasets where module discovery has been performed.}

\item{test}{datasets to test for preservation of modules from each
\emph{discovery} dataset.}

\item{nCores}{number of cores to parallelise the permutation procedure over.}

\item{nPerm}{number of permutations to use. Can be specified as a vector if
a different number of permutations is desired for each discovery dataset.
If not specified, the number of permutations will be automatically
determined (see details).}

\item{excludeModules}{optional list of vectors containing modules to exclude
from the analysis for each \code{discovery} dataset. If unspecified, the
preservation of all modules will be tested.}

\item{includeModules}{optional list of vectors containing modules to include
in the analysis for each \code{discovery} dataset. If unspecified, the
preservation of all modules will be tested.}

\item{null}{the type of null model, either "overlap" or "all" (see details).}

\item{alternative}{The type of module preservation test to perform. Must be
one of "greater" (default), "less" or "two.sided" (see details).}

\item{simplify}{logical; if \code{TRUE}, simplify the structure of the output
list if possible (see Return Value).}

\item{verbose}{logical; should progress be reported? Default is \code{TRUE}.}

\item{keepNulls}{logical; if \code{TRUE}, the null distributions are returned
 as part of the output.}
}
\value{
The returned data structure is organised as a nested list of lists, which
 should be accessed as \code{results[[discovery]][[test]]}. If
 \code{simplify} is set to \code{TRUE}, then this structure will be
 simplified as much as possible depending on the combination of dataset
 comparisons that have been performed. For each dataset-comparison a list of
 the following objects are returned:
 \itemize{
   \item{\code{observed}:}{
     A matrix of the observed values for the module preservation statistics.
     Rows correspond to modules, and columns to the module preservation
     statistics.
   }
   \item{\code{nulls}:}{
     A three dimensional array containing the values of the module
     preservation statistics evaluated on random permutation of module
     assignment in the test network. Rows correspond to modules, columns to
     the module preservation statistics, and the third dimension to the
     permutations.
   }
   \item{\code{p.values}:}{
     A matrix of p-values for the \code{observed} module preservation
     statistics as evaluated through a permutation test using the
     corresponding values in \code{nulls}.
   }
   \item{\code{nGenesPresent}:}{
     A vector containing the number of genes that are present in the test
     dataset for each module.
   }
   \item{\code{propGenesPresent}:}{
     A vector containing the proportion of genes present in the test dataset
     for each module. Modules where this is less than 1 should be
     investigated further before making judgements about preservation to
     ensure that the missing genes are not the most connected ones.
   }
   \item{\code{contingency}:}{
     If \code{moduleAssignments} are present for both the \emph{discovery}
     and \emph{test} datasets, then a contigency table showing the overlap
     between modules across datasets is returned. Rows correspond to modules
     in the \emph{discovery} dataset, columns to modules in the \emph{test}
     dataset.
   }
 }
}
\description{
Assess whether gene coexpression modules replicate or are preserved in an
independent dataset. Module preservation is assessed using a permutation
procedure performed on seven module preservation statistics (see details).
Each dataset requires a precalculated coexpression network and adjecency
network (see details). Providing the gene expression is optional, but
recommended. Matrix data is ideally stored in the
\code{\link[=bigMatrix-class]{bigMatrix}} format (see details).
}
\details{
\subsection{Input data structure:}{
  The topological properties used to assess module preservation are designed
  for networks constructed using Weighted Gene Coexpression Network Analysis
  (\pkg{\link[WGCNA]{WGCNA}}, \emph{(3)}). These are calculated from the gene expression
  for each dataset, the pairwise correlation between genes (coexpression) for
  each dataset, and the pairwise gene adjacencies (adjacency) for each
  dataset. The adjacency is typically the absolute value of the correlation
  raised to a power to penalise weak correlations \emph{(3)}. Module
  preservation can also be assessed on networks without the gene expression
  data, but only a limited subset of the statistics will be calculated.
  Network modules are usually clusters of tightly coexpressed genes
  \emph{(3)}, but the procedure is also useful for assessing known gene sets,
  i.e. pathways across conditions or tissues \emph{(1)}.

  The arguments \code{geneExpression}, \code{coexpression}, and
  \code{adjacency} each expect a \code{\link{list}} where each element
  contains the matrix data for each respective dataset. This matrix data
  should be stored as a 'bigMatrix' object (see
  \link[=bigMatrix-get]{converting matrix data to 'bigMatrix' data}).
  Similarly, the \code{moduleAssignments} argument expects a list of named
  vectors, which contain the the module assignments for each gene in the
  respective dataset. List elements corresponding to datasets where module
  discovery has not been performed should contain \code{NULL}, unless the
  datasets are named throughout the function arguments. I.e. where the
  \code{\link{names}} of \code{geneExpression}, \code{coexpression}, and
  \code{adjacency} correspond to the names of each dataset of interest, the
  names of the \code{discovery} dataset can be used to look up the respective
  module assignments in the \code{moduleAssignments} list. If module
  discovery has only been performed in one dataset, then the
  \code{moduleAssignments} will also accept a named vector.

  The \code{discovery} arguments specifies which dataset the \code{modules}
  of interest were discovered in, and the \code{test} argument specifies
  which dataset to test the replication/preservation of each module.
}
\subsection{'bigMatrix' vs. 'matrix' input data:}{
  Although the function expects \code{\link[=bigMatrix-class]{bigMatrix}}
  data, regular 'matrix' objects are also accepted. In this case, the
  'matrix' data is temporarily converted to 'bigMatrix' by the function. This
  conversion process involves writing out each matrix as a binary file on
  disk, which can take a long time for large datasets. It is strongly
  recommended for the user to store their data as 'bigMatrix' objects, as the
  \link{networkProperties} function, \link[=plotModule]{plotting}
  \link[=plotTopology]{functions}, \link[=geneOrder]{gene} and
  \link[=sampleOrder]{sample} ordering also expect 'bigMatrix' objects.
  Further, 'bigMatrix' objects have a number of benefits, including
  instantaneous load time from any future R session, and parallel access from
  mutliple independent R sessions. Methods are provided for
  \link[=bigMatrix-get]{converting to, loading in}, and
  \link[=bigMatrix-out]{writing out} 'bigMatrix' objects.
}
\subsection{Memory usage:}{
  A trade off has been made between memory usage and computation time.
  'modulePreservation' has a large memory overhead as it requires
  pre-computed coexpression and adjacency matrices for each dataset. However,
  these are stored in shared memory, which means that each parallel process
  can independently access this memory. There is very little memory overhead
  for each additional core.

  Although this also means that the matrices can be larger than the available
  RAM, in practice we find that this slows down the procedure by several
  orders of magnitude. For optimal performance, there should be sufficient
  memory to load in each gene expression, coexpression, and adjacency matrix
  for each dataset. Note: most of this memory is cached; matrices are only
  loaded into RAM when needed (i.e. for the dataset pair for a comparison),
  so the physical amount of RAM used will be much lower.
}
\subsection{Module Preservation Statistics:}{
 Module preservation is assessed through seven statistics \emph{(1)}:
 \enumerate{
   \item{\code{mean.adj}:}{
     The mean adjacency, or module density, measures how densely connected a
     module is in the \emph{test} dataset.
   }
   \item{\code{pve}:}{
     Short for "the proportion of variance explained in the underlying gene
     expression data for the module by its summary expression profile in the
     \emph{test} dataset". The summary expression profile is calculated as
     the first eigenvector from a principal component analysis on the
     module's (scaled) gene expression data. The summary expression profile
     is commonly referred to as the "module eigengene (ME)", and abbreviated
     as \code{propVarExpl} in \emph{(1)}.
   }
   \item{\code{cor.coexp}:}{
     The correlation of coexpression patterns for a module across the
     \emph{discovery} and \emph{test} datasets. It is also referred to as
     the "correlation of correlation" and abbreviated as \code{cor.cor} in
     \emph{(1)}.
   }
   \item{\code{cor.kIM}:}{
     The correlation of intramodular connectivity across the \emph{discovery}
     and \emph{test} datasets. Intramodular connectivity is quantified as the
     sum of adjacency for a gene to all other genes in the module.
   }
   \item{\code{cor.MM}:}{
     The correlation of intramodular module membership across the
     \emph{discovery} and \emph{test} datasets. Module membership denotes the
     correlation between each gene and the summary expression profile for
     that module in the given dataset. The statistic is abbreviated as
     \code{cor.kME} in \emph{(1)}.
   }
   \item{\code{mean.coexp}:}{
     The mean sign-aware coexpression measures the average coexpression for a
     module in the \emph{test} dataset, multiplied by the sign of the
     coexpression in the \emph{discovery} dataset. It assesses how strongly
     correlated the genes are in the test dataset (in either direction),
     penalising the module if any gene pairs whose correlation flips between
     datasets. It is also referred to as the "mean sign-aware correlation"
     and abbreviated as \code{mean.cor} in \emph{(1)}.
   }
   \item{\code{mean.MM}:}{
     The mean sign-aware module membership measures the average module
     membership in the \emph{test} dataset, multiplied by the sign of the
     module membership in the \emph{discovery} dataset. It measures how
     coherent the gene expression is in the \emph{test} dataset, penalising
     the module if any genes are differentially expressed compared to the
     module in one, but not both \emph{discovery} and \emph{test} datasets.
     It is also abbreivated as \code{mean.kME} in \emph{(1)}.
   }
 }
}
\subsection{Hypothesis testing:}{
 Three alternative hypotheses are available. "greater", the default, tests
 whether each module preservation statistic is larger than expected by
 chance. "lesser" tests whether each module preservation statistic is smaller
 than expected by chance, which may be useful for identifying modules that
 are extremely different in the \emph{test} dataset. "two.sided" can be used
 to test both alternate hypotheses.

 To determine whether a module preservation statistic deviates from chance, a
 permutation procedure is employed. Each statistic is calculated between the
 module in the \emph{discovery} dataset and \code{nPerm} random gene sets of
 the same size in the \emph{test} dataset in order to assess the distribution
 of each statistic under the null hypothesis. Two models for the null
 hypothesis are available. Under "overlap", the default, random sampling is
 performed only for the set of genes present in both the \emph{discovery} and
 \emph{test} datasets. Alternative, the argument \code{null} can be set to
 "all", in which case random sampling is performed on all genes present in
 the \emph{test} dataset. The latter may be suitable when assessing module
 replication across species.

 The number of permutations required for any given significance threshold is
 approximately 1 / the desired significance for one sided tests, and double
 that for two-sided tests. This can be calculated with
 \code{\link{requiredPerms}}. When \code{nPerm} is not specified, the number
 of permutations is automatically calculated as the number required for a
 Bonferroni corrected significance threshold adjusting for the total number
 of tests for each statistic, i.e. the total number of modules to be analysed
 multiplied by the number of \emph{test} datasets each module is tested in.
 Although assessing the replication of a small numberof modules calls for
 very few permutations, we recommend using no fewer than 1,000 as fewer
 permutations are unlikely to generate representative null distributions.
 \strong{Note:} the assumption used by \code{\link{requiredPerms}} to
 determine the correct number of permtutations breaks down when assessing the
 preservation of modules in a very small dataset (e.g. gene sets in a dataset
 with less than 100 genes total). However, the reported p-values will still
 be accurate (see \code{\link{perm.test}}) \emph{(2)}.
}
}
\examples{
\dontrun{
set.seed(1)

## Example 1: Assess replication of all modules from one
## cohort in an independent dataset

# First we need some example data
geA <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geA) <- paste0("Gene_", 1:100)
rownames(geA) <- paste0("CohortA_", 1:50)
coexpA <- cor(geA) # coexpression
adjA <- abs(coexpA)^5 # adjacency
moduleAssignments <- sample(1:7, size=100, replace=TRUE)
names(moduleAssignments) <- paste0("Gene_", 1:100)

geB <- matrix(rnorm(70*100), ncol=100) # gene expression
colnames(geB) <- paste0("Gene_", 1:100)
rownames(geB) <- paste0("CohortB_", 1:70)
coexpB <- cor(geB) # coexpression
adjB <- abs(coexpB)^6 # adjacency

# Now format the data for input to modulePreservation
geneExpression <- list(
  cohortA=as.bigMatrix(geA, "geA_bm"),
  cohortB=as.bigMatrix(geA, "geA_bm")
)
coexpression <- list(
  cohortA=as.bigMatrix(coexpA, "coexpA_bm"),
  cohortB=as.bigMatrix(coexpB, "coexpB_bm")
)
adjacency <- list(
  cohortA=as.bigMatrix(adjA, "adjA_bm"),
  cohortB=as.bigMatrix(adjB, "adjB_bm")
)

# Assess module preservation, using two cores
replication <- modulePreservation(
  geneExpression, coexpression, adjacency, moduleAssignments,
  nCores=2
)

## Example 2: assess replication of two disease-associated modules
replication <- modulePreservation(
  geneExpression, coexpression, adjacency, moduleAssignments,
  nCores=2, includeModules = c("4", "7")
)

## Example 3: exclude a module from the analysis
replication <- modulePreservation(
  geneExpression, coexpression, adjacency, moduleAssignments,
  nCores=2, excludeModules = "0"
)

## Example 4: assess preservation of modules across multiple
## tissues
geAdipose <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geAdipose) <- paste0("Gene_", 1:100)
rownames(geAdipose) <- paste0("Sample_", 1:50)
coexpAdipose <- cor(geAdipose) # coexpression
adjAdipose <- abs(coexpAdipose)^5 # adjacency
adiposeModules <- sample(0:7, size=100, replace=TRUE)
names(adiposeModules) <- paste0("Gene_", 1:100)

geLiver <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geLiver) <- paste0("Gene_", 1:100)
rownames(geLiver) <- paste0("Sample_", 1:50)
coexpLiver <- cor(geLiver) # coexpression
adjLiver <- abs(coexpLiver)^6 # adjacency
liverModules <- sample(0:12, size=100, replace=TRUE)
names(liverModules) <- paste0("Gene_", 1:100)

geHeart <- matrix(rnorm(50*100), ncol=100) # gene expression
colnames(geHeart) <- paste0("Gene_", 1:100)
rownames(geHeart) <- paste0("Sample_", 1:50)
coexpHeart <- cor(geHeart) # coexpression
adjHeart <- abs(coexpHeart)^4 # adjacency
heartModules <- sample(0:5, size=100, replace=TRUE)
names(heartModules) <- paste0("Gene_", 1:100)

# Now format the data for input to modulePreservation
geneExpression <- list(
  adipose=as.bigMatrix(geAdipose, "geAdipose_bm"),
  liver=as.bigMatrix(geLiver, "geLiver_bm"),
  heart=as.bigMatrix(geHeart, "geHeart_bm")
)
coexpression <- list(
  adipose=as.bigMatrix(coexpAdipose, "coexpAdipose_bm"),
  liver=as.bigMatrix(coexpLiver, "coexpLiver_bm"),
  heart=as.bigMatrix(coexpHeart, "coexpHeart_bm")
)
adjacency <- list(
  adipose=as.bigMatrix(adjAdipose, "adjAdipose_bm"),
  liver=as.bigMatrix(adjLiver, "adjLiver_bm"),
  heart=as.bigMatrix(adjHeart, "adjHeart_bm")
)
moduleAssignments <- list(
  adipose=adiposeModules, liver=liverModules, heart=heartModules
)

# Assess the preservation of each module in each non-discovery
# tissue.
preservation <- modulePreservation(
  geneExpression, coexpression, adjacency, moduleAssignments,
  nCores=2, discovery=c("adipose", "liver", "heart"),
  test=c("adipose", "liver", "heart")
)

# Remove bigMatrix files used in examples
unlink("*_bm*")
}
}
\references{
\enumerate{
    \item{
      Langfelder, P., Luo, R., Oldham, M. C. & Horvath, S. \emph{Is my
      network module preserved and reproducible?} PLoS Comput. Biol.
      \strong{7}, e1001057 (2011).
    }
    \item{
      Phipson, B. & Smyth, G. K. \emph{Permutation P-values should never be
      zero: calculating exact P-values when permutations are randomly drawn.}
      Stat. Appl. Genet. Mol. Biol. \strong{9}, Article39 (2010).
    }
    \item{
      Langfelder, P. & Horvath, S. \emph{WGCNA: an R package for weighted
      correlation network analysis.} BMC Bioinformatics \strong{9}, 559
      (2008).
    }
  }
}

