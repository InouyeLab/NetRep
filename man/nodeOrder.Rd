% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/downstream-analysis.R
\name{nodeOrder}
\alias{nodeOrder}
\title{Order nodes and modules within a network.}
\usage{
nodeOrder(data = NULL, correlation, network, moduleAssignments = NULL,
  modules = NULL, backgroundLabel = "0", discovery = NULL, test = NULL,
  nCores = NULL, na.rm = FALSE, orderModules = TRUE, simplify = TRUE,
  verbose = TRUE)
}
\arguments{
\item{data}{a list of numeric matrices. Each entry of the list corresponds to
a dataset and contains the data used to infer the interaction network
between variables (e.g. genes). Expects matrix columns to correspond to
variables and matrix rows to correspond to samples.}

\item{correlation}{a list of matrices. Each entry of the list corresponds to a 
dataset and contains an \eqn{n * n} matrix of the correlation between 
each pair of variables in the dataset.}

\item{network}{a list of matrices. Each entry of the list corresponds to a 
dataset and contains an \eqn{n * n} matrix of the network edge weights 
between each pair of variables in the dataset.}

\item{moduleAssignments}{a vector containing the module each variable belongs
to in the discovery dataset. If there are multiple discovery datasets 
then this argument should be a list of such vectors.}

\item{modules}{a list of vectors, one for each \code{discovery} dataset, 
of modules to perform the analysis on. The default is to analyse all modules
in each \code{discovery} dataset, with the exception of those specified in 
\code{backgroundLabel}.}

\item{backgroundLabel}{a single label that nodes that do not belong to any
module are assigned. The default is "0".}

\item{discovery}{a vector of names or indices denoting the discovery dataset(s).}

\item{test}{a list of vectors of names or indices denoting the test datasets
for each \code{discovery} dataset. Alternatively can be provided as vector
if the test datasets are the same for all 'discovery' datasets (e.g. for 
performing a pairwise comparison).}

\item{nCores}{number of cores to parallelise the calculation of network 
properties over. Ignored if the user has already registered a parallel 
backend.If \code{NULL} (default) the maximum number of cores on the machine
will be used.}

\item{na.rm}{logical; If \code{TRUE}, nodes and moduels present in the 
\code{discovery} dataset but missing from the test dataset are excluded. If
\code{FALSE}, missing nodes and modules are put last in the ordering.}

\item{orderModules}{logical; if \code{TRUE} modules ordered by clustering 
their summary vectors. If \code{FALSE} modules are returned in the order
provided.}

\item{simplify}{logical; if \code{TRUE}, simplify the structure of the output
list if possible (see Return Value).}

\item{verbose}{logical; should progress be reported? Default is \code{TRUE}.}
}
\value{
A nested list structure. At the top level, the list has one element per 
 \code{'discovery'} dataset. Each of these elements is a list that has one
 element per \code{'test'} dataset analysed for that \code{'discovery'} 
 dataset. Each of these elements is a list that has one element per 
 \code{'modules'} specified, containing a vector of node names for the
 requested module. If \code{simplify = TRUE}, then there will be a single
 vector of node names for each \code{'test'} dataset.
}
\description{
Order nodes in descending order of \emph{weighted degree} and order 
modules by the similarity of their summary vectors.
}
\details{
\subsection{Input data structure:}{
  This function allows for input data formatted in a number of ways. Where 
  there are multiple datasets of interest (e.g. multiple tissues, locations, 
  or a discovery dataset and an independent test dataset) the arguments 
  \code{data}, \code{correlation}, and \code{network} should be
  \code{\link[=list]{lists}} where each element contains the matrix data for 
  each respective dataset. Alternatively, if only one dataset is of interest, 
  the \code{data}, \code{correlation}, and \code{network} arguments
  will also each accept a 'matrix' object.
  
  Similarly, the \code{moduleAssignments} argument expects a list of named
  vectors, which denote the module each variable belongs to in the discovery
  dataset. If module discovery has only been performed in one dataset, then 
  the \code{moduleAssignments} argument will also accept a named vector.
  
  The \code{discovery} arguments specifies which dataset the \code{modules} 
  of interest were discovered in, and the \code{test} argument specifies 
  which dataset to calculate the network properties in. These arguments are
  ignored if data is provided for only one dataset.
}
\subsection{'bigMatrix' vs. 'matrix' input data:}{
  Although the function expects \code{\link[=bigMatrix-class]{bigMatrix}} 
  data, regular 'matrix' objects are also accepted. In this case, the 
  'matrix' data is temporarily converted to 'bigMatrix' by the function. This
  conversion process involves writing out each matrix as a binary file on 
  disk, which can take a long time for large datasets. It is strongly 
  recommended for the user to store their data as 'bigMatrix' objects, as the
  \link{modulePreservation} function, \link[=plotModule]{plotting} 
  \link[=plotTopology]{functions}, \link[=nodeOrder]{node} and 
  \link[=sampleOrder]{sample} ordering functions also expect 'bigMatrix'
  objects. Further, 'bigMatrix' objects have a number of benefits, including 
  instantaneous load time from any future R session, and parallel access from
  mutliple independent R sessions. Methods are provided for 
  \link[=bigMatrix-get]{converting to, loading in}, and 
  \link[=bigMatrix-out]{writing out} 'bigMatrix' objects.
}
}
\examples{
\dontrun{
# load in example data, correlation, and network matrices for a discovery and test dataset:
data("netrep_example")

# Convert them to the 'bigMatrix' format:
discovery_data <- as.bigMatrix(discovery_data)
discovery_correlation <- as.bigMatrix(discovery_correlation)
discovery_network <- as.bigMatrix(discovery_network)
test_data <- as.bigMatrix(test_data)
test_correlation <- as.bigMatrix(test_correlation)
test_network <- as.bigMatrix(test_network)

# Set up input lists for each input matrix type across datasets:
data_list <- list(discovery=discovery_data, test=test_data)
correlation_list <- list(discovery=discovery_correlation, test=test_correlation)
network_list <- list(discovery=discovery_network, test=test_network)
labels_list <- list(discovery=module_labels)

# Sort nodes by module similarity and node degree
nodes <- nodeOrder(
  data=data_list, correlation=correlation_list, network=network_list, 
  moduleAssignments=labels_list
)
}

}
\references{
\enumerate{
   \item{
     Langfelder, P., Mischel, P. S. & Horvath, S. \emph{When is hub gene 
     selection better than standard meta-analysis?} PLoS One \strong{8}, 
     e61505 (2013).
   }
}
}
\seealso{
\code{\link{networkProperties}}
}

