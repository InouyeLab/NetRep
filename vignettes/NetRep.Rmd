---
title: "NetRep"
author: "Scott Ritchie"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document: 
    keep_md: true
abstract: >
  Introduction to NetRep with example workflow on simulated data
vignette: >
  %\VignetteIndexEntry{NetRep}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo=FALSE, cache=FALSE}
options(width = 100)
```

## Introduction

The *NetRep* package provides functions for assessing the reproducibility and
preservation of network modules across datasets. The preservation of network 
modules in a second dataset is quantified through a permutation procedure that 
tests whether topological properties are more similar in the test dataset than
expected by chance: \emph{i.e.} when calculated between a module in the 
*discovery* dataset and random groups of nodes in the *test* dataset. 

This type of analysis is suitable for networks that can be meaningfully inferred
from multiple datasets. These include gene coexpression networks,
protein-protein interaction networks, and microbial interaction networks.
Modules within these networks consist of groups of nodes that are particularly
interesting: for example a group of tightly connected genes associated with a
disease, groups of genes annotated with the same term in the Gene Ontology
database, or groups of interacting microbial species, i.e. communities.
Application of this method can answer questions such as; (1) do the
relationships between genes in a module replicate in an independent cohort? (2)
are these gene coexpression modules preserved across tissues or tissue specific?
(3) are these modules conserved across species? (4) are microbial communities
preseved across multiple spatial locations
    
A typical workflow for a NetRep analysis will usually contain the following steps:

1. Calculate correlation structure and infer networks in each dataset using some
   network construction algorithm.
2. Save the correlation structure and network adjacency matrices in as 
   `bigMatrix` objects using the *NetRep* package.
3. Run the `modulePreservation` analysis to determine which modules are 
   significantly preserved/reproducible in your test dataset(s).
4. Caculate the topological properties of nodes for your modules of interest.
5. Visualise your modules of interest.

This vignette will cover each of these steps, and is structured into sections 
for each step.

## Data required for a NetRep analysis

Any *NetRep* analysis requires the following data to be provided/pre-computed 
for each dataset to be analysed:

 - An adjacency matrix whose entries indicate the strength of the relationship 
   between nodes.
 - A matrix whose entries contain the correlation coefficient between each pair
   of nodes in the network.
 - A "data matrix", which contains the data used to calculate the correlation
   structure and infer the network, e.g. gene expression data.

Additionally, a vector containing the module label for each node in the network
is required for each discovery dataset.

There are many different approaches to network inference and module detection.
For gene expression data, we recommend using Weighted Gene Coexpression Network
Analysis through the [WGCNA][1] package. 

[1]: https://cran.r-project.org/web/packages/WGCNA/index.html

*NetRep* will also work with other types of data and networks defined through 
other algorithms, however you should read the sections on the module 
preservation statistics, sparse data, proportional data, and hypothesis testing 
in the details section of the help file for the `modulePreservation` function 
(`help("modulePreservation", package="NetRep")`) to determine the correct 
runtime parameters for your analysis.

For this vignette, we will use gene expression data simulated for two 
independent cohorts. The *discovery* dataset was simulated to contain four 
modules of varying size, two of which (Modules 1 and 4) replicate in the *test* 
dataset. 

This data is provided with the *NetRep* package: 

```{r}
library("NetRep")
data("NetRep")
```

Details of the simulation are provided in the documentation for the 
package data (see `help("NetRep-data")`).

The previous command loads seven objects into the R session:

```{r}
ls()
```

  - `discovery_data`: a matrix with 150 columns (genes) and 30 rows (samples) 
     whose entries correspond to the expression level of each gene in each 
     sample in the discovery dataset.
  - `discovery_correlation`: a matrix with 150 columns and 150 rows containing 
     the correlation-coefficients between each pair of genes calculated from the 
    `discovery_data` matrix.
  - `discovery_network`: a matrix with 150 columns and 150 rows containing the 
     network edge weights encoding the interaction strength between each pair of 
     genes in the discovery dataset.
  - `module_labels`: a named vector with 150 entries containing the module 
     assignment for each gene as identified in the discovery dataset.
  - `test_data`: a matrix with 150 columns (genes) and 30 rows (samples) whose 
     entries correspond to the expression level of each gene in each sample in 
     the test dataset.
  - `test_correlation`: a matrix with 150 columns and 150 rows containing the 
     correlation-coefficients between each pair of genes calculated from the 
    `test_data` matrix.
  - `test_network`: a matrix with 150 columns and 150 rows containing the 
     network edge weights encoding the interaction strength between each pair of
     genes in the test dataset.
     
## Saving the data in shared memory

```{r, message=FALSE, echo=FALSE}
# This is hidden so the script will run. The other code blocks are demonstrative:
# they show the user how to use the 'backingfile' argument. This is primarily for
# people who are going to copy code from the vignette and modify it to their 
# data (e.g. most people), however the vignette should not save things to the
# user's current directory when they build the vignette 
discovery_data <- as.bigMatrix(discovery_data)
discovery_correlation <- as.bigMatrix(discovery_correlation)
discovery_network <- as.bigMatrix(discovery_network)
test_data <- as.bigMatrix(test_data)
test_correlation <- as.bigMatrix(test_correlation)
test_network <- as.bigMatrix(test_network)
```

*NetRep* requires the `data`, `correlation` and `network` adjacency matrices to
be saved as `bigMatrix` objects. These are pointers to shared memory backed by
files on disk. This allows *NetRep* to efficiently run in parallel: the multiple
parallel R sessions will access the same data in memory, rather than requiring
copies of each matrix to be stored in the memory of each parallel R session.

**Note:** It is **important** that we run *NetRep* in a new R session that 
*only* has these `bigMatrix` objects (and the module assignments) in it to 
minimise the memory usage of the permutation procedure!

Typically, we would save these matrices as `bigMatrix` objects in our network 
inference scripts:

```{r, eval=FALSE}
# Save data in the 'bigMatrix' format in your current directory.
save.as.bigMatrix(discovery_data, backingfile="discovery_data.bm")
save.as.bigMatrix(discovery_correlation, backingfile="discovery_correlation.bm")
save.as.bigMatrix(discovery_network, backingfile="discovery_network.bm")
save.as.bigMatrix(test_data, backingfile="test_data.bm")
save.as.bigMatrix(test_correlation, backingfile="test_correlation.bm")
save.as.bigMatrix(test_network, backingfile="test_network.bm")

# Write out the module assignments vector to file to be read in by the module
# preservation script we write later.
write.csv(module_labels, file="discovery_modules.csv")
```

Alternatively, you could write a script to read in these matrices from a file
using `read.table` then save them in the `bigMatrix` format. 

Once saved in the `bigMatrix` format (this might take a few hours for large 
networks) we can instantly load these into any new R session in the future:

```{r, eval=FALSE}
discovery_network <- load.bigMatrix("discovery_network.bm")
```

These can be manipulated like regular matrices:

```{r, hold=TRUE}
discovery_network[1:5, 1:5]
```

And converted back for functions that will only work on `matrix` objects:

```{r, eval=FALSE}
# This converts a `bigMatrix` to a `matrix` in R, but leaves the 
# backingfile on disk so you can still instantly load it in other
# R sessions using 'load.bigMatrix'
as.matrix(discovery_network)
```

## Running the module preservation analysis

The following code is a script that will run the module preservation analysis.

**This should be run in a new R session with nothing else loaded in 
it**.

```{r, eval=FALSE}
# First, we need to load in the data we previously saved in 
# the `bigMatrix` format:
discovery_data <- load.bigMatrix("discovery_data.bm")
discovery_correlation <- load.bigMatrix("discovery_correlation.bm")
discovery_network <- load.bigMatrix("discovery_network.bm")
test_data <- load.bigMatrix("test_data.bm")
test_correlation <- load.bigMatrix("test_correlation.bm")
test_network <- load.bigMatrix("test_network.bm")

# As well as read in the module labels:
module_labels <- read.csv("module_labels.csv", stringsAsFactors=FALSE)
# Convert the 'data.frame' to a 'vector'
module_labels <- structure(module_labels[,2], names=module_labels[,1])

# Set up the input data structures for NetRep:
data_list <- list(discovery=discovery_data, test=test_data)
correlation_list <- list(discovery=discovery_correlation, test=test_correlation)
network_list <- list(discovery=discovery_network, test=test_network)

# Assess the preservation of modules in the test dataset 
preservation <- modulePreservation(
 data=data_list, correlation=correlation_list, network=network_list,
 moduleAssignments=module_labels, nPerm=10000, discovery="discovery", 
 test="test"
)

# Write out the results object:
saveRDS(preservation, "preservation-analysis-results.rds")
```

```{r, echo=FALSE, hold=TRUE}
# This is the code that actually gets run in the Rmarkdown document
data_list <- list(discovery=discovery_data, test=test_data)
correlation_list <- list(discovery=discovery_correlation, test=test_correlation)
network_list <- list(discovery=discovery_network, test=test_network)

preservation <- modulePreservation(
 data=data_list, correlation=correlation_list, network=network_list,
 moduleAssignments=module_labels, nPerm=10000, discovery="discovery", 
 test="test", verbose=FALSE
)
```

First, this script loads in the `bigMatrix` objects we saved earlier in the 
vignette, and reads in the module assignments for genes in the discovery 
dataset.

Next, we combine these objects into list structures for *NetRep*. All functions 
in the *NetRep* package have the following arguments:

 - `network`: a list of interaction networks, one for each dataset.
 - `data`: a list of data matrices used to infer those networks, one for each 
    dataset.
 - `correlation`: a list of matrices containing the pairwise correlation 
    coefficients between variables/nodes in each dataset.
 - `moduleAssignments`: a list of vectors, one for each *discovery* dataset, 
    containing the module assignments for each node in that dataset.
 - `modules`: a list of vectors, one vector for each *discovery* dataset, 
    containing the names of the modules from that dataset to analyse.
 - `discovery`: a vector indicating the names or indices to use as the 
   *discovery* datasets in the `network`, `data`, `correlation`, 
   `moduleAssignments`, and `modules` arguments.
 - `test`: a list of vectors, one vector for each *discovery* dataset, 
    containing the names or indices of the `network`, `data`, and `correlation` 
    argument lists to use as the *test* dataset(s) for the analysis of each 
   *discovery* dataset.


